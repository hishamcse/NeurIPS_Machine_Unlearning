{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc6d17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:03.374437Z",
     "iopub.status.busy": "2024-02-24T05:58:03.374098Z",
     "iopub.status.idle": "2024-02-24T05:58:08.920727Z",
     "shell.execute_reply": "2024-02-24T05:58:08.919932Z"
    },
    "executionInfo": {
     "elapsed": 8461,
     "status": "ok",
     "timestamp": 1707625017849,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "LSoU_A-5MfGE",
    "papermill": {
     "duration": 5.563825,
     "end_time": "2024-02-24T05:58:08.923072",
     "exception": false,
     "start_time": "2024-02-24T05:58:03.359247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import time\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69300aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:08.952475Z",
     "iopub.status.busy": "2024-02-24T05:58:08.952030Z",
     "iopub.status.idle": "2024-02-24T05:58:08.956786Z",
     "shell.execute_reply": "2024-02-24T05:58:08.955914Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1707625017850,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "t8VOu7tzMfGG",
    "papermill": {
     "duration": 0.021877,
     "end_time": "2024-02-24T05:58:08.958806",
     "exception": false,
     "start_time": "2024-02-24T05:58:08.936929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It's really important to add an accelerator to your notebook, as otherwise the submission will fail.\n",
    "# We recomment using the P100 GPU rather than T4 as it's faster and will increase the chances of passing the time cut-off threshold.\n",
    "\n",
    "if DEVICE != 'cuda':\n",
    "    raise RuntimeError('Make sure you have added an accelerator to your notebook; the submission will fail otherwise!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb8923",
   "metadata": {
    "id": "zCvo3SiNMfGH",
    "papermill": {
     "duration": 0.012648,
     "end_time": "2024-02-24T05:58:08.984509",
     "exception": false,
     "start_time": "2024-02-24T05:58:08.971861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e75838",
   "metadata": {
    "id": "PnoRAql-MfGJ",
    "papermill": {
     "duration": 0.012709,
     "end_time": "2024-02-24T05:58:09.010219",
     "exception": false,
     "start_time": "2024-02-24T05:58:08.997510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seed Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33c6935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.038730Z",
     "iopub.status.busy": "2024-02-24T05:58:09.038332Z",
     "iopub.status.idle": "2024-02-24T05:58:09.052487Z",
     "shell.execute_reply": "2024-02-24T05:58:09.051629Z"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1707625017850,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "zgXmjtFVMfGK",
    "outputId": "f19e40c9-7dbc-49da-a9cd-38cf394fe587",
    "papermill": {
     "duration": 0.031171,
     "end_time": "2024-02-24T05:58:09.054366",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.023195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e275cd99ad0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3047)\n",
    "\n",
    "G_retain = torch.Generator()\n",
    "G_retain.manual_seed(20)\n",
    "\n",
    "G_forget = torch.Generator()\n",
    "G_forget.manual_seed(30)\n",
    "\n",
    "G_validate = torch.Generator()\n",
    "G_validate.manual_seed(40)\n",
    "\n",
    "G_test = torch.Generator()\n",
    "G_test.manual_seed(40)\n",
    "\n",
    "\n",
    "G_unexp_retain = torch.Generator()\n",
    "G_unexp_retain.manual_seed(50)\n",
    "\n",
    "G_unexp_forget = torch.Generator()\n",
    "G_unexp_forget.manual_seed(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aff86d",
   "metadata": {
    "id": "CWltcHCoMfGL",
    "papermill": {
     "duration": 0.012924,
     "end_time": "2024-02-24T05:58:09.080695",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.067771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing Version or Submission Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ac1bb",
   "metadata": {
    "id": "aFSEDpU8MfGM",
    "papermill": {
     "duration": 0.01303,
     "end_time": "2024-02-24T05:58:09.106866",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.093836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here at the time of **testing**, we will keep the **internet on**, set **test=True** and load pretrained cifar10 model to test our unlearning algorithm implementation. In this case, we will utilize some parts from the given starting kit by the competition organizers.<br>\n",
    "**Link:** https://github.com/unlearning-challenge/starting-kit/blob/main/unlearning-CIFAR10.ipynb <br><br>\n",
    "At the time of **submission**, **internet off** and **test=False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a276e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.134554Z",
     "iopub.status.busy": "2024-02-24T05:58:09.134210Z",
     "iopub.status.idle": "2024-02-24T05:58:09.138356Z",
     "shell.execute_reply": "2024-02-24T05:58:09.137460Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1707625017851,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "EKzRMQBHMfGM",
    "papermill": {
     "duration": 0.020272,
     "end_time": "2024-02-24T05:58:09.140156",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.119884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "# test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9e16b",
   "metadata": {
    "id": "nWFnLAbDMfGM",
    "papermill": {
     "duration": 0.01307,
     "end_time": "2024-02-24T05:58:09.166447",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.153377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa945f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.194296Z",
     "iopub.status.busy": "2024-02-24T05:58:09.193976Z",
     "iopub.status.idle": "2024-02-24T05:58:09.208317Z",
     "shell.execute_reply": "2024-02-24T05:58:09.207324Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1707625017851,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "RmJHHGahMfGN",
    "papermill": {
     "duration": 0.030556,
     "end_time": "2024-02-24T05:58:09.210168",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.179612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for loading the CIFAR10 dataset.\n",
    "\n",
    "if test:\n",
    "\n",
    "    # The directory for a dataset and a pretrained model\n",
    "    test_dir = './test'\n",
    "    test_model_path = os.path.join(test_dir, \"weights_resnet18_cifar10.pth\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    class PublicDataset(Dataset):\n",
    "\n",
    "        def __init__(self, ds: Dataset):\n",
    "            self._ds = ds\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._ds)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            item = self._ds[index]\n",
    "            result = {\n",
    "                'image': item[0],\n",
    "                'image_id': index,\n",
    "                'age_group': item[1],\n",
    "                'age': item[1],\n",
    "                'person_id': index,\n",
    "            }\n",
    "            return result\n",
    "\n",
    "    def get_dataset(batch_size_r, batch_size_f,batch_size_vt, thinning_param: int=1, root=test_dir) -> tuple[DataLoader, DataLoader, DataLoader, DataLoader]:\n",
    "\n",
    "        # utils\n",
    "        normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ]) # ??\n",
    "\n",
    "        # create dataset\n",
    "        train_set = torchvision.datasets.CIFAR10(root=test_dir, train=True, download=True, transform=normalize)\n",
    "        train_ds = PublicDataset(train_set)\n",
    "\n",
    "        # download the forget and retain index split\n",
    "        local_path = \"forget_idx.npy\"\n",
    "        if not os.path.exists(local_path):\n",
    "            response = requests.get(\n",
    "                \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "            )\n",
    "            open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "        forget_idx = np.load(local_path)\n",
    "\n",
    "        # construct indices of retain from those of the forget set\n",
    "        forget_mask = np.zeros(len(train_set.targets), dtype=bool)\n",
    "        forget_mask[forget_idx] = True\n",
    "        retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
    "\n",
    "        # split train set into a forget and a retain set\n",
    "        forget_ds = Subset(train_ds, forget_idx)\n",
    "        retain_ds = Subset(train_ds, retain_idx)\n",
    "\n",
    "        full_val_set = torchvision.datasets.CIFAR10(root=test_dir, train=False, download=True, transform=normalize)\n",
    "\n",
    "        test_set, val_set = torch.utils.data.random_split(full_val_set, [0.5, 0.5])\n",
    "\n",
    "        val_ds = PublicDataset(val_set)\n",
    "        test_ds = PublicDataset(test_set)\n",
    "\n",
    "        retain_loader = DataLoader(retain_ds, batch_size=batch_size_r, shuffle=True, generator=G_retain)\n",
    "        forget_loader = DataLoader(forget_ds, batch_size=batch_size_f, shuffle=True, generator=G_forget)\n",
    "        validation_loader = DataLoader(val_ds, batch_size=batch_size_vt, shuffle=True, generator=G_validate)\n",
    "        test_loader = DataLoader(test_ds, batch_size=batch_size_vt, shuffle=True, generator=G_test)\n",
    "\n",
    "        return retain_loader, forget_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6e1e8",
   "metadata": {
    "id": "6sTsK8i6MfGS",
    "papermill": {
     "duration": 0.012992,
     "end_time": "2024-02-24T05:58:09.236483",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.223491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Using Loss & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e78f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.264427Z",
     "iopub.status.busy": "2024-02-24T05:58:09.264076Z",
     "iopub.status.idle": "2024-02-24T05:58:09.271115Z",
     "shell.execute_reply": "2024-02-24T05:58:09.270190Z"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1707625139250,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "FYoYNataMfGT",
    "papermill": {
     "duration": 0.023447,
     "end_time": "2024-02-24T05:58:09.273079",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.249632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_acc_loss(net, dataloader, criterion):\n",
    "    net.eval()\n",
    "    total_samp = 0\n",
    "    total_acc = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for sample in dataloader:\n",
    "        images, labels = sample['image'].to(DEVICE), sample['age_group'].to(DEVICE)\n",
    "        _pred = net(images).to(DEVICE)\n",
    "        total_samp += len(labels)\n",
    "        loss = criterion(_pred, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += (_pred.max(1)[1] == labels).float().sum().item()\n",
    "\n",
    "    mean_loss = total_loss / len(dataloader)\n",
    "    mean_acc = total_acc / total_samp * 100.0\n",
    "\n",
    "    return mean_loss, mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d36d31",
   "metadata": {
    "id": "1OubkB_bMfGU",
    "papermill": {
     "duration": 0.057495,
     "end_time": "2024-02-24T05:58:09.344102",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.286607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss Acc Evaluation & Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94cb980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.372796Z",
     "iopub.status.busy": "2024-02-24T05:58:09.372158Z",
     "iopub.status.idle": "2024-02-24T05:58:09.378605Z",
     "shell.execute_reply": "2024-02-24T05:58:09.377743Z"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1707627135033,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "AwZUXWITgXyT",
    "papermill": {
     "duration": 0.022944,
     "end_time": "2024-02-24T05:58:09.380667",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.357723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def printAccLoss(net):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  l, a = calculate_acc_loss(net, retain_loader, criterion)\n",
    "  print(f\"Retain set accuracy: {a:0.2f}%\")\n",
    "  print(f\"Retain set loss: {l:0.2f}\")\n",
    "  l, a = calculate_acc_loss(net, forget_loader, criterion)\n",
    "  print(f\"Forget set accuracy: {a:0.2f}%\")\n",
    "  print(f\"Forget set loss: {l:0.2f}\")\n",
    "  l, a = calculate_acc_loss(net, validation_loader, criterion)\n",
    "  print(f\"Validation set accuracy: {a:0.2f}%\")\n",
    "  print(f\"Validation set loss: {l:0.2f}\")\n",
    "  l, a = calculate_acc_loss(net, test_loader, criterion)\n",
    "  print(f\"Test set accuracy: {a:0.2f}%\")\n",
    "  print(f\"Test set loss: {l:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03fb2b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.408834Z",
     "iopub.status.busy": "2024-02-24T05:58:09.408241Z",
     "iopub.status.idle": "2024-02-24T05:58:09.436326Z",
     "shell.execute_reply": "2024-02-24T05:58:09.435396Z"
    },
    "papermill": {
     "duration": 0.044542,
     "end_time": "2024-02-24T05:58:09.438586",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.394044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sampleLoss(net, sample, criterion):\n",
    "  inputs = sample[\"image\"].to(DEVICE)\n",
    "  labels = sample['age_group'].to(DEVICE)\n",
    "  outputs = net(inputs).to(DEVICE)\n",
    "  loss = criterion(outputs,  labels)\n",
    "  return loss\n",
    "\n",
    "def grads(net, sample, criterion):\n",
    "  loss = sampleLoss(net, sample, criterion)\n",
    "  loss.backward()\n",
    "  g = {}\n",
    "  with torch.no_grad():\n",
    "    for name, param in net.named_parameters():\n",
    "      if param.grad != None:\n",
    "        # g.append(param.grad.clone())\n",
    "        g[name] = param.grad.clone()\n",
    "  return g\n",
    "\n",
    "def gradsToDevice(net, sample, criterion):\n",
    "  loss = sampleLoss(net, sample, criterion)\n",
    "  loss.backward()\n",
    "  g = {}\n",
    "  with torch.no_grad():\n",
    "    for name, param in net.named_parameters():\n",
    "      if param.grad != None:\n",
    "        # g.append(param.grad.clone())\n",
    "        g[name] = param.grad.clone().to(DEVICE)\n",
    "  return g\n",
    "\n",
    "\n",
    "def gradsFlat(net, sample, criterion):\n",
    "  loss = sampleLoss(net, sample, criterion)\n",
    "  loss.backward()\n",
    "  g = []\n",
    "  with torch.no_grad():\n",
    "    for param in net.parameters():\n",
    "      if param.grad != None:\n",
    "        g.append(torch.flatten(param.grad))\n",
    "    return torch.cat(g)\n",
    "\n",
    "\n",
    "def unitDotProduct(a, b):\n",
    "  a = torch.flatten(a)\n",
    "  b = torch.flatten(b)\n",
    "\n",
    "  return torch.nn.functional.cosine_similarity(a, b,dim = 0)\n",
    "\n",
    "def findComponent(direction1, vector1):\n",
    "    direction = torch.flatten(direction1)\n",
    "    vector = torch.flatten(vector1)\n",
    "    dotProd = torch.dot(direction , vector)\n",
    "    dirMagSquared = torch.dot(direction, direction)\n",
    "    return ((dotProd / dirMagSquared) * direction).view_as(direction1)\n",
    "\n",
    "def compareGradFlattenedAll(net, fLoader, rLoader, epochs, lr, unit):\n",
    "  net.train()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  for _ in range(epochs):\n",
    "    print(f\"epoch : {_ + 1}\")\n",
    "    for fsample in fLoader:\n",
    "      # fsample = next(iter(fLoader))\n",
    "      rsample = next(iter(rLoader))\n",
    "#       rgrads = grads(net, rsample, criterion)\n",
    "#       fgrads = grads(net, fsample, criterion)\n",
    "      r = gradsFlat(net, rsample, criterion)\n",
    "      f = gradsFlat(net, fsample, criterion)\n",
    "\n",
    "      with torch.no_grad():\n",
    "        componentInDirOfrgrad = findComponent(r, f)\n",
    "        perp = f - componentInDirOfrgrad\n",
    "        for param in net.parameters():\n",
    "          i = 0\n",
    "          if param.grad != None:\n",
    "            sz = param.numel()\n",
    "#             print(sz)\n",
    "            cgradf = perp[i : i + sz]\n",
    "            i += sz\n",
    "            cgrad = cgradf.view_as(param)\n",
    "            norm = torch.norm(cgradf)\n",
    "            if norm == 0 :\n",
    "              continue\n",
    "            cgrad /= norm\n",
    "            param += lr * cgrad\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "\n",
    "def compareGradFlattenedAll2(net, fLoader, rLoader, epochs, lr, unit, beta = .9):\n",
    "  net.train()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  perpC = 0\n",
    "    \n",
    "  for _ in range(epochs):\n",
    "    print(f\"epoch : {_ + 1}\")\n",
    "    for fsample in fLoader:\n",
    "      # fsample = next(iter(fLoader))\n",
    "      rsample = next(iter(rLoader))\n",
    "      rgrads = grads(net, rsample, criterion)\n",
    "      fgrads = grads(net, fsample, criterion)\n",
    "\n",
    "      with torch.no_grad():\n",
    "        rgf = []\n",
    "        fgf = []\n",
    "        indices = {}\n",
    "        lens = {}\n",
    "        lastIndex = 0\n",
    "\n",
    "        for key in rgrads.keys():\n",
    "          r = rgrads[key]\n",
    "          f = fgrads[key]\n",
    "          rf = torch.flatten(r)\n",
    "          ff = torch.flatten(f)\n",
    "\n",
    "          indices[key] = lastIndex\n",
    "          lens[key] = rf.shape[0]\n",
    "          lastIndex += rf.shape[0]\n",
    "\n",
    "          rgf.append(rf)\n",
    "          fgf.append(ff)\n",
    "\n",
    "        r = torch.cat(rgf)\n",
    "        f = torch.cat(fgf)\n",
    "        componentInDirOfrgrad = findComponent(r, f)\n",
    "        perp = f - componentInDirOfrgrad\n",
    "        if unit:\n",
    "            norm = torch.norm(perp)\n",
    "            if norm == 0:\n",
    "                continue\n",
    "            perp /= norm\n",
    "        \n",
    "        perpC = beta * perpC + (1 - beta) * perp\n",
    "        perp = perpC\n",
    "        # print(indices)\n",
    "\n",
    "        for name, param in net.named_parameters():\n",
    "          if param.grad != None:\n",
    "            cgradf = perp[indices[name] : indices[name] + lens[name]]\n",
    "            cgrad = cgradf.view_as(param)\n",
    "#             if unit:\n",
    "#               norm = torch.norm(cgradf)\n",
    "#               if norm == 0 :\n",
    "#                 continue\n",
    "#               cgrad /= norm\n",
    "            # print(f\"name : {name}, grad : {cgrad}\")\n",
    "            # print(f\"torch norm : {torch.norm(cgradf)}\")\n",
    "            param += lr * cgrad\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "def getModel():\n",
    "  test_dir = './test'\n",
    "  local_path = \"weights_resnet18_cifar10.pth\"\n",
    "  test_model_path = os.path.join(test_dir, local_path)\n",
    "  if not os.path.exists(test_model_path):\n",
    "    response = requests.get(\n",
    "        \"https://storage.googleapis.com/unlearning-challenge/\" + local_path)\n",
    "    open(test_model_path, \"wb\").write(response.content)\n",
    "  net = resnet18(weights=None, num_classes=10)\n",
    "  net.load_state_dict(torch.load(test_model_path, map_location = DEVICE))\n",
    "  return net\n",
    "\n",
    "def freezeBN(net):\n",
    "  for name, module in net.named_modules():\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "      module.eval()\n",
    "      for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unlearning(net, forget_loader, retain_loader, vLoader):\n",
    "#     freezeBN(net)\n",
    "    compareGradFlattenedAll(net, forget_loader, retain_loader, 12, .002, True)\n",
    "    compareGradFlattenedAll(net, retain_loader, forget_loader, 3, -.002, True)\n",
    "    compareGradFlattenedAll(net, retain_loader, forget_loader, 1, -.001, True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1301b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.467535Z",
     "iopub.status.busy": "2024-02-24T05:58:09.466869Z",
     "iopub.status.idle": "2024-02-24T05:58:09.471700Z",
     "shell.execute_reply": "2024-02-24T05:58:09.470824Z"
    },
    "papermill": {
     "duration": 0.021276,
     "end_time": "2024-02-24T05:58:09.473613",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.452337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "    retain_loader, forget_loader, validation_loader, test_loader = get_dataset(64, 64, 64)\n",
    "#     r,f, vt\n",
    "    forget = get_dataset(64, 128, 64)\n",
    "    retain = get_dataset(256, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01376da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.501028Z",
     "iopub.status.busy": "2024-02-24T05:58:09.500694Z",
     "iopub.status.idle": "2024-02-24T05:58:09.507118Z",
     "shell.execute_reply": "2024-02-24T05:58:09.506261Z"
    },
    "papermill": {
     "duration": 0.022465,
     "end_time": "2024-02-24T05:58:09.509165",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.486700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "    addNoiseList = ['layer4.0.conv1','layer4.0.conv2', 'layer4.0.downsample','layer4.0.downsample.0','layer4.0.downsample.1', 'layer4.1.conv1', 'layer4.1.conv2','fc']\n",
    "    freezeList = ['conv1','bn1','layer1','layer1.0','layer1.0.conv1','layer1.0.bn1','layer1.0.conv2','layer1.0.bn2','layer1.1','layer1.1.conv1','layer1.1.bn1','layer1.1.conv2','layer1.1.bn2','layer2','layer2.0','layer2.0.conv1','layer2.0.bn1','layer2.0.conv2','layer2.0.bn2','layer2.0.downsample','layer2.0.downsample.0','layer2.0.downsample.1','layer2.1','layer2.1.conv1','layer2.1.bn1','layer2.1.conv2','layer2.1.bn2','layer3','layer3.0','layer3.0.conv1','layer3.0.bn1','layer3.0.conv2','layer3.0.bn2','layer3.0.downsample','layer3.0.downsample.0','layer3.0.downsample.1','layer3.1','layer3.1.conv1','layer3.1.bn1','layer3.1.conv2','layer3.1.bn2','layer4.0.bn1','layer4.0.bn2','layer4.1.bn1','layer4.1.bn2']\n",
    "\n",
    "    net = getModel()\n",
    "    net = net.to(DEVICE)\n",
    "    freezeBN(net)\n",
    "    # freeze(net, freezeList)\n",
    "    # addNoise(net, addNoiseList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7e04e",
   "metadata": {
    "papermill": {
     "duration": 0.012971,
     "end_time": "2024-02-24T05:58:09.535450",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.522479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "256 -> 257\n",
    "128 -> 257\n",
    "64 -> 237\n",
    "mix -> 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea150da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.563377Z",
     "iopub.status.busy": "2024-02-24T05:58:09.563036Z",
     "iopub.status.idle": "2024-02-24T05:58:09.569315Z",
     "shell.execute_reply": "2024-02-24T05:58:09.568447Z"
    },
    "papermill": {
     "duration": 0.022754,
     "end_time": "2024-02-24T05:58:09.571325",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.548571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if test:\n",
    "    start_time = time.time()\n",
    "#     compareGradFlattenedAll(net, forget_loader, retain_loader, 12, .002, True)\n",
    "#     compareGradFlattenedAll2(net, forget[1], forget[0], 6, .05, True)\n",
    "#     compareGradFlattenedAll2(net, forget[1], forget[0], 3, .01, True)\n",
    "#     compareGradFlattenedAll2(net, retain[0], retain[1], 4, -.05, True)\n",
    "    \n",
    "    compareGradFlattenedAll2(net, forget[1], forget[0], 5, .02, True, .9)\n",
    "    compareGradFlattenedAll2(net, retain[0], retain[1], 3, -.02, True,  .9)\n",
    "    \n",
    "    \n",
    "#     compareGradFlattenedAll(net, retain_loader, forget_loader, 3, -.002, True)\n",
    "#     compareGradFlattenedAll2(net, retain[0], retain[1], 3, -.002, True)\n",
    "    \n",
    "    \n",
    "#     compareGradFlattenedAll2(net, forget[1], forget[0], 2, .05, True)\n",
    "#     compareGradFlattenedAll2(net, retain[0], retain[1], 1, -.01, True)\n",
    "    \n",
    "    \n",
    "#     compareGradFlattenedAll2(net, forget[1], forget[0], 2, .05, True)\n",
    "#     compareGradFlattenedAll2(net, retain[0], retain[1], 1, -.01, True)\n",
    "\n",
    "    \n",
    "#     compareGradFlattenedAll2(net, forget[1], forget[0], 2, .05, True)\n",
    "#     compareGradFlattenedAll2(net, retain[0], retain[1], 1, -.01, True)\n",
    "\n",
    "#     unlearning(net, forget_loader, retain_loader, validation_loader)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3cadc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.599609Z",
     "iopub.status.busy": "2024-02-24T05:58:09.599019Z",
     "iopub.status.idle": "2024-02-24T05:58:09.603213Z",
     "shell.execute_reply": "2024-02-24T05:58:09.602341Z"
    },
    "papermill": {
     "duration": 0.020383,
     "end_time": "2024-02-24T05:58:09.605146",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.584763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "    printAccLoss(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe6841db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.632576Z",
     "iopub.status.busy": "2024-02-24T05:58:09.632022Z",
     "iopub.status.idle": "2024-02-24T05:58:09.636232Z",
     "shell.execute_reply": "2024-02-24T05:58:09.635371Z"
    },
    "papermill": {
     "duration": 0.020067,
     "end_time": "2024-02-24T05:58:09.638203",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.618136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "    printAccLoss(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66241cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.666794Z",
     "iopub.status.busy": "2024-02-24T05:58:09.665838Z",
     "iopub.status.idle": "2024-02-24T05:58:09.670601Z",
     "shell.execute_reply": "2024-02-24T05:58:09.669693Z"
    },
    "papermill": {
     "duration": 0.021234,
     "end_time": "2024-02-24T05:58:09.672627",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.651393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "    compareGradFlattenedAll(net, forget_loader, retain_loader, 12, .002, True)\n",
    "    printAccLoss(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e23b5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.700424Z",
     "iopub.status.busy": "2024-02-24T05:58:09.700138Z",
     "iopub.status.idle": "2024-02-24T05:58:09.704774Z",
     "shell.execute_reply": "2024-02-24T05:58:09.703862Z"
    },
    "papermill": {
     "duration": 0.020957,
     "end_time": "2024-02-24T05:58:09.706859",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.685902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "#     compareGradFlattenedAll(net, retain_loader, forget_loader , 3, -.002, True)\n",
    "    compareGradFlattenedAll(net, retain_loader, forget_loader , 1, -.001, True)\n",
    "\n",
    "    printAccLoss(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078f3e6",
   "metadata": {
    "id": "RQLnj5N_MfGV",
    "papermill": {
     "duration": 0.013089,
     "end_time": "2024-02-24T05:58:09.733364",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.720275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparison With Trained Model Exclusively on Retain Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1e381",
   "metadata": {
    "id": "pFswBaAaokRM",
    "papermill": {
     "duration": 0.01297,
     "end_time": "2024-02-24T05:58:09.759578",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.746608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "------------ Base Model ---------------\n",
    "\n",
    "Retain set accuracy: 99.48%\n",
    "\n",
    "Retain set loss: 1.97%\n",
    "\n",
    "Forget set accuracy: 99.32%\n",
    "\n",
    "Forget set loss: 2.17%\n",
    "\n",
    "Validation set accuracy: 88.28%\n",
    "\n",
    "Validation set loss: 44.61%\n",
    "\n",
    "Test set accuracy: 89.00%\n",
    "\n",
    "Test set loss: 44.96%\n",
    "\n",
    "\n",
    "------------ Unlearned Model ---------------\n",
    "\n",
    "Retain set accuracy: 99.48%\n",
    "\n",
    "Retain set loss: 1.97%\n",
    "\n",
    "Forget set accuracy: 99.32%\n",
    "\n",
    "Forget set loss: 2.16%\n",
    "\n",
    "Validation set accuracy: 88.36%\n",
    "\n",
    "Validation set loss: 46.37%\n",
    "\n",
    "Test set accuracy: 88.92%\n",
    "\n",
    "Test set loss: 44.01%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c20d7f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.787802Z",
     "iopub.status.busy": "2024-02-24T05:58:09.787088Z",
     "iopub.status.idle": "2024-02-24T05:58:09.793397Z",
     "shell.execute_reply": "2024-02-24T05:58:09.792503Z"
    },
    "executionInfo": {
     "elapsed": 51778,
     "status": "ok",
     "timestamp": 1706894799634,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "0V83K3QgMfGV",
    "outputId": "fc0ede93-6bf4-4e08-db6c-628406d18693",
    "papermill": {
     "duration": 0.022493,
     "end_time": "2024-02-24T05:58:09.795245",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.772752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    # download weights of a model trained exclusively on the retain set\n",
    "    local_path = \"retrain_weights_resnet18_cifar10.pth\"\n",
    "    if not os.path.exists(local_path):\n",
    "        response = requests.get(\n",
    "            \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
    "        )\n",
    "        open(local_path, \"wb\").write(response.content)\n",
    "\n",
    "    weights_pretrained = torch.load(local_path, map_location=DEVICE)\n",
    "\n",
    "    # load model with pre-trained weights\n",
    "    rt_model = resnet18(weights=None, num_classes=10)\n",
    "    rt_model.load_state_dict(weights_pretrained)\n",
    "    rt_model.to(DEVICE)\n",
    "    rt_model.eval()\n",
    "\n",
    "    # test criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    printAccLoss(rt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0070686",
   "metadata": {
    "_kg_hide-input": false,
    "id": "AwEFtc0iMfGV",
    "papermill": {
     "duration": 0.013241,
     "end_time": "2024-02-24T05:58:09.821662",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.808421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation using MIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1b7d1",
   "metadata": {
    "id": "hwVp2CHMMfGW",
    "papermill": {
     "duration": 0.012906,
     "end_time": "2024-02-24T05:58:09.847839",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.834933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Reference:** https://github.com/unlearning-challenge/starting-kit/blob/main/unlearning-CIFAR10.ipynb<br>\n",
    "We will evaluate the trained models using Simple Membership Inference Attacks(MIA). This is **not used** as evaluation metric for the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a2b9f",
   "metadata": {
    "id": "ZfKpaB2nMfGW",
    "papermill": {
     "duration": 0.012846,
     "end_time": "2024-02-24T05:58:09.873797",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.860951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This MIA consists of a **logistic regression model** that predicts whether the model was trained on a particular sample from that sample's loss. To get an idea on the difficulty of this problem, we first plot below a histogram of the losses of the pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5c6c9",
   "metadata": {
    "id": "7v1QjSxJMfGW",
    "papermill": {
     "duration": 0.014052,
     "end_time": "2024-02-24T05:58:09.901050",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.886998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87db7757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.929245Z",
     "iopub.status.busy": "2024-02-24T05:58:09.928403Z",
     "iopub.status.idle": "2024-02-24T05:58:09.935084Z",
     "shell.execute_reply": "2024-02-24T05:58:09.934075Z"
    },
    "id": "dlL1TthRMfGX",
    "papermill": {
     "duration": 0.022834,
     "end_time": "2024-02-24T05:58:09.936982",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.914148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    def compute_losses(model_, loader):\n",
    "        \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        all_losses = []\n",
    "\n",
    "        for sample in loader:\n",
    "            images, labels = sample['image'].to(DEVICE), sample['age_group'].to(DEVICE)\n",
    "            logits = model_(images)\n",
    "\n",
    "            losses = criterion(logits, labels).numpy(force=True)\n",
    "            for l in losses:\n",
    "                all_losses.append(l)\n",
    "\n",
    "        return np.array(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d2dfb01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:09.965064Z",
     "iopub.status.busy": "2024-02-24T05:58:09.964249Z",
     "iopub.status.idle": "2024-02-24T05:58:09.973119Z",
     "shell.execute_reply": "2024-02-24T05:58:09.972232Z"
    },
    "executionInfo": {
     "elapsed": 26447,
     "status": "ok",
     "timestamp": 1706890396287,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "uC8PXRKWMfGX",
    "outputId": "5c8470d2-9482-4289-d8f2-fdb7ce2d1622",
    "papermill": {
     "duration": 0.024885,
     "end_time": "2024-02-24T05:58:09.975084",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.950199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    # load model with pre-trained weights\n",
    "    model = resnet18(weights=None, num_classes=10)\n",
    "    weights_pretrained = torch.load(test_model_path, map_location=DEVICE)\n",
    "    model.load_state_dict(weights_pretrained)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    retain_losses = compute_losses(model, retain_loader)\n",
    "    forget_losses = compute_losses(model, forget_loader)\n",
    "    test_losses = compute_losses(model, test_loader)\n",
    "\n",
    "    plt.title(\"Losses on retain, forget and validation set (pre-trained model)\")\n",
    "    plt.hist(retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "    plt.hist(forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    plt.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    plt.xlabel(\"Loss\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.xlim((0, np.max(test_losses)))\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(frameon=False, fontsize=14)\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ec2ea",
   "metadata": {
    "id": "U3mF4XyoMfGY",
    "papermill": {
     "duration": 0.012936,
     "end_time": "2024-02-24T05:58:10.001523",
     "exception": false,
     "start_time": "2024-02-24T05:58:09.988587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As per the above plot, the distributions of losses are quite different between the train and validation sets, as expected. In what follows, we will define an MIA that leverages the fact that examples that were trained on have smaller losses compared to examples that weren't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280d280",
   "metadata": {
    "id": "_rXlfIFWMfGY",
    "papermill": {
     "duration": 0.013007,
     "end_time": "2024-02-24T05:58:10.027809",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.014802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MIA Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3929c8c",
   "metadata": {
    "id": "esOZYRpyMfGY",
    "papermill": {
     "duration": 0.015484,
     "end_time": "2024-02-24T05:58:10.056604",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.041120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we will define an MIA that leverages the fact that examples that were trained on have smaller losses compared to examples that weren't. Using this fact, the simple MIA defined below will aim to infer whether the forget set was in fact part of the training set.\n",
    "\n",
    "This MIA is defined below. It takes as input the per-sample losses of the unlearned model on forget and test examples, and a membership label (0 or 1) indicating which of those two groups each sample comes from. It then returns the cross-validation accuracy of a linear model trained to distinguish between the two classes.\n",
    "\n",
    "Intuitively, an unlearning algorithm is successful with respect to this simple metric if the attacker isn't able to distinguish the forget set from the test set any better than it would for the ideal unlearning algorithm (retraining from scratch without the retain set); see the last part of this MIA section for additional discussion and for computing that reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ea4fbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.090182Z",
     "iopub.status.busy": "2024-02-24T05:58:10.089770Z",
     "iopub.status.idle": "2024-02-24T05:58:10.097300Z",
     "shell.execute_reply": "2024-02-24T05:58:10.096262Z"
    },
    "id": "ZRqEfrKgMfGZ",
    "papermill": {
     "duration": 0.026984,
     "end_time": "2024-02-24T05:58:10.099616",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.072632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    def simple_mia(sample_loss, members, n_splits=10, random_state=42):\n",
    "        \"\"\"Computes cross-validation score of a membership inference attack.\n",
    "\n",
    "        Args:\n",
    "          sample_loss : array_like of shape (n,).\n",
    "            objective function evaluated on n samples.\n",
    "          members : array_like of shape (n,),\n",
    "            whether a sample was used for training.\n",
    "          n_splits: int\n",
    "            number of splits to use in the cross-validation.\n",
    "        Returns:\n",
    "          scores : array_like of size (n_splits,)\n",
    "        \"\"\"\n",
    "\n",
    "        unique_members = np.unique(members)\n",
    "        if not np.all(unique_members == np.array([0, 1])):\n",
    "            raise ValueError(\"members should only have 0 & 1s\")\n",
    "\n",
    "        attack_model = linear_model.LogisticRegression()\n",
    "        cv = model_selection.StratifiedShuffleSplit(\n",
    "            n_splits=n_splits, random_state=random_state\n",
    "        )\n",
    "        return model_selection.cross_val_score(\n",
    "            attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521912c6",
   "metadata": {
    "id": "IZBYkAn_MfGZ",
    "papermill": {
     "duration": 0.013216,
     "end_time": "2024-02-24T05:58:10.126534",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.113318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MIA on Original Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37873c",
   "metadata": {
    "id": "9iTYheR8MfGZ",
    "papermill": {
     "duration": 0.014006,
     "end_time": "2024-02-24T05:58:10.154211",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.140205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As a reference point, we first compute the accuracy of the MIA on the original model to distinguish between the forget set and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2430e1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.184566Z",
     "iopub.status.busy": "2024-02-24T05:58:10.184234Z",
     "iopub.status.idle": "2024-02-24T05:58:10.190757Z",
     "shell.execute_reply": "2024-02-24T05:58:10.189840Z"
    },
    "executionInfo": {
     "elapsed": 1732,
     "status": "ok",
     "timestamp": 1706890439917,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "QlUw830KMfGn",
    "outputId": "66b7ba15-ed01-459c-93f7-6c8ce59cb833",
    "papermill": {
     "duration": 0.024524,
     "end_time": "2024-02-24T05:58:10.192989",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.168465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    forget_losses = compute_losses(model, forget_loader)\n",
    "\n",
    "    # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "    np.random.shuffle(forget_losses)\n",
    "    forget_losses = forget_losses[: len(test_losses)]\n",
    "\n",
    "    samples_mia = np.concatenate((test_losses, forget_losses)).reshape((-1, 1))\n",
    "    labels_mia = [0] * len(test_losses) + [1] * len(forget_losses)\n",
    "\n",
    "    mia_scores = simple_mia(samples_mia, labels_mia)\n",
    "\n",
    "    print(f\"The MIA has an accuracy of {mia_scores.mean():.3f} on forgotten vs unseen images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3efe8",
   "metadata": {
    "id": "3H22Stq4MfGn",
    "papermill": {
     "duration": 0.014281,
     "end_time": "2024-02-24T05:58:10.222171",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.207890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MIA on Unlearned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceaefe0",
   "metadata": {
    "id": "Hnqc6F9eMfGn",
    "papermill": {
     "duration": 0.014291,
     "end_time": "2024-02-24T05:58:10.250943",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.236652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll now compute the accuracy of the MIA on the unlearned model. We expect the MIA to be less accurate on the unlearned model than on the original model, since the original model has not undergone a procedure to unlearn the forget set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2738b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.281567Z",
     "iopub.status.busy": "2024-02-24T05:58:10.280928Z",
     "iopub.status.idle": "2024-02-24T05:58:10.287265Z",
     "shell.execute_reply": "2024-02-24T05:58:10.286369Z"
    },
    "executionInfo": {
     "elapsed": 20473,
     "status": "ok",
     "timestamp": 1706894820030,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "Kk1WvOCLMfGo",
    "outputId": "fda5d8f5-8099-484f-cac5-de0f71e38b68",
    "papermill": {
     "duration": 0.023952,
     "end_time": "2024-02-24T05:58:10.289329",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.265377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    net_forget_losses = compute_losses(net, forget_loader)\n",
    "    net_retain_losses = compute_losses(net, retain_loader)\n",
    "    net_test_losses = compute_losses(net, test_loader)\n",
    "\n",
    "    np.random.shuffle(net_forget_losses)\n",
    "    net_forget_losses = net_forget_losses[: len(test_losses)]\n",
    "\n",
    "    net_samples_mia = np.concatenate((net_test_losses, net_forget_losses)).reshape((-1, 1))\n",
    "    labels_mia = [0] * len(net_test_losses) + [1] * len(net_forget_losses)\n",
    "\n",
    "    net_mia_scores = simple_mia(net_samples_mia, labels_mia)\n",
    "\n",
    "    print(f\"The MIA has an accuracy of {net_mia_scores.mean():.3f} on forgotten vs unseen images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333eab5f",
   "metadata": {
    "id": "74_BQPrQMfGo",
    "papermill": {
     "duration": 0.014197,
     "end_time": "2024-02-24T05:58:10.318217",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.304020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparison With Original Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e6b7",
   "metadata": {
    "id": "VY45LU4hMfGo",
    "papermill": {
     "duration": 0.013799,
     "end_time": "2024-02-24T05:58:10.345853",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.332054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From the score above, the MIA is indeed less accurate on the unlearned model than on the original model, as expected. Finally, we'll plot the histogram of losses of the unlearned model on the train and validation set. From the below figure, we can observe that the distributions of forget and validation losses are more similar under the unlearned model compared to the original model, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "477d9cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.376154Z",
     "iopub.status.busy": "2024-02-24T05:58:10.375791Z",
     "iopub.status.idle": "2024-02-24T05:58:10.385475Z",
     "shell.execute_reply": "2024-02-24T05:58:10.384581Z"
    },
    "id": "kY1m57laMfGp",
    "papermill": {
     "duration": 0.02745,
     "end_time": "2024-02-24T05:58:10.387541",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.360091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_title(f\"Pre-trained model.\\nAttack accuracy: {mia_scores.mean():0.2f}\")\n",
    "    ax1.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    ax1.hist(forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    ax1.hist(retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "\n",
    "    ax2.set_title(f\"Unlearned by fine-tuning.\\nAttack accuracy: {net_mia_scores.mean():0.2f}\")\n",
    "    ax2.hist(net_test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    ax2.hist(net_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    ax2.hist(net_retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "\n",
    "    ax1.set_xlabel(\"Loss\")\n",
    "    ax2.set_xlabel(\"Loss\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax1.set_xlim((0, np.max(test_losses)))\n",
    "    ax2.set_xlim((0, np.max(test_losses)))\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    ax1.legend(frameon=False, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f2f05",
   "metadata": {
    "id": "SXAq9FAVMfGp",
    "papermill": {
     "duration": 0.013508,
     "end_time": "2024-02-24T05:58:10.414751",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.401243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparison With Trained Model Exclusively on Retain Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fb560",
   "metadata": {
    "id": "b6m--iA_MfGp",
    "papermill": {
     "duration": 0.013781,
     "end_time": "2024-02-24T05:58:10.442151",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.428370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since our goal is to approximate the model that has been trained only on the retain set, we'll consider that the gold standard is the score achieved by this model. Intuitively, we expect the MIA accuracy to be around 0.5, since for such a model, both the forget and test set are unseen samples from the same distribution. However, a number of factors such as distribution shift or class imbalance can make this number vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7d5ba",
   "metadata": {
    "id": "ABF7k_fkMfGq",
    "papermill": {
     "duration": 0.013169,
     "end_time": "2024-02-24T05:58:10.468822",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.455653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we will compute the MIA score on Re-trained model exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc3f9474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.497665Z",
     "iopub.status.busy": "2024-02-24T05:58:10.496851Z",
     "iopub.status.idle": "2024-02-24T05:58:10.503017Z",
     "shell.execute_reply": "2024-02-24T05:58:10.502139Z"
    },
    "id": "7aJvO4rzMfGq",
    "papermill": {
     "duration": 0.022883,
     "end_time": "2024-02-24T05:58:10.505042",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.482159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    rt_test_losses = compute_losses(rt_model, test_loader)\n",
    "    rt_forget_losses = compute_losses(rt_model, forget_loader)\n",
    "    rt_retain_losses = compute_losses(rt_model, retain_loader)\n",
    "\n",
    "    rt_samples_mia = np.concatenate((rt_test_losses, rt_forget_losses)).reshape((-1, 1))\n",
    "    labels_mia = [0] * len(rt_test_losses) + [1] * len(rt_forget_losses)\n",
    "\n",
    "    rt_mia_scores = simple_mia(rt_samples_mia, labels_mia)\n",
    "\n",
    "    print(f\"The MIA has an accuracy of {rt_mia_scores.mean():.3f} on forgotten vs unseen images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b332d7c",
   "metadata": {
    "id": "Qmx-4lCiMfGq",
    "papermill": {
     "duration": 0.013367,
     "end_time": "2024-02-24T05:58:10.532298",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.518931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, as we've done before, let's compare the histograms of this ideal algorithm (re-trained model) vs the model obtain from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1de6ac41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.561410Z",
     "iopub.status.busy": "2024-02-24T05:58:10.560653Z",
     "iopub.status.idle": "2024-02-24T05:58:10.572342Z",
     "shell.execute_reply": "2024-02-24T05:58:10.571451Z"
    },
    "id": "GGDgArmhMfGq",
    "papermill": {
     "duration": 0.028323,
     "end_time": "2024-02-24T05:58:10.574223",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.545900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if test:\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_title(f\"Original model.\\nAttack accuracy: {mia_scores.mean():0.2f}\")\n",
    "    ax1.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    ax1.hist(forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    ax1.hist(retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "\n",
    "    ax2.set_title(f\"Re-trained model.\\nAttack accuracy: {rt_mia_scores.mean():0.2f}\")\n",
    "    ax2.hist(rt_test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    ax2.hist(rt_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    ax2.hist(rt_retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "\n",
    "    ax3.set_title(f\"Unlearned by fine-tuning.\\nAttack accuracy: {net_mia_scores.mean():0.2f}\")\n",
    "    ax3.hist(net_test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
    "    ax3.hist(net_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
    "    ax3.hist(net_retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
    "\n",
    "    ax1.set_xlabel(\"Loss\")\n",
    "    ax2.set_xlabel(\"Loss\")\n",
    "    ax3.set_xlabel(\"Loss\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax3.set_yscale(\"log\")\n",
    "    ax1.set_xlim((0, np.max(test_losses)))\n",
    "    ax2.set_xlim((0, np.max(test_losses)))\n",
    "    ax3.set_xlim((0, np.max(test_losses)))\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "    ax1.legend(frameon=False, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c0ecd",
   "metadata": {
    "id": "YGKaZaL-MfGr",
    "papermill": {
     "duration": 0.013384,
     "end_time": "2024-02-24T05:58:10.601359",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.587975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f75ba166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.630242Z",
     "iopub.status.busy": "2024-02-24T05:58:10.629524Z",
     "iopub.status.idle": "2024-02-24T05:58:10.641654Z",
     "shell.execute_reply": "2024-02-24T05:58:10.640760Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707625018979,
     "user": {
      "displayName": "Abdur Rafi",
      "userId": "03245871940225266893"
     },
     "user_tz": -360
    },
    "id": "LUHQqVCpMfGO",
    "papermill": {
     "duration": 0.028698,
     "end_time": "2024-02-24T05:58:10.643559",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.614861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions for loading the hidden dataset.\n",
    "\n",
    "if not test:\n",
    "\n",
    "    def load_example(df_row):\n",
    "        image = torchvision.io.read_image(df_row['image_path'])\n",
    "        result = {\n",
    "            'image': image,\n",
    "            'image_id': df_row['image_id'],\n",
    "            'age_group': df_row['age_group'],\n",
    "            'age': df_row['age'],\n",
    "            'person_id': df_row['person_id']\n",
    "        }\n",
    "        return result\n",
    "\n",
    "\n",
    "    class HiddenDataset(Dataset):\n",
    "        '''The hidden dataset.'''\n",
    "        def __init__(self, split='train'):\n",
    "            super().__init__()\n",
    "            self.examples = []\n",
    "\n",
    "            df = pd.read_csv(f'/kaggle/input/neurips-2023-machine-unlearning/{split}.csv')\n",
    "            df['image_path'] = df['image_id'].apply(\n",
    "                lambda x: os.path.join('/kaggle/input/neurips-2023-machine-unlearning/', 'images', x.split('-')[0], x.split('-')[1] + '.png'))\n",
    "            df = df.sort_values(by='image_path')\n",
    "            df.apply(lambda row: self.examples.append(load_example(row)), axis=1)\n",
    "            if len(self.examples) == 0:\n",
    "                raise ValueError('No examples.')\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.examples)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            example = self.examples[idx]\n",
    "            image = example['image']\n",
    "            image = image.to(torch.float32)\n",
    "            example['image'] = image\n",
    "            return example\n",
    "\n",
    "\n",
    "    def get_dataset(batch_size_r, batch_size_f, batch_size_v):\n",
    "        '''Get the dataset.'''\n",
    "        retain_ds = HiddenDataset(split='retain')\n",
    "        forget_ds = HiddenDataset(split='forget')\n",
    "        val_ds = HiddenDataset(split='validation')\n",
    "\n",
    "        retain_loader = DataLoader(retain_ds, batch_size=batch_size_r, shuffle=True, generator=G_retain)\n",
    "        forget_loader = DataLoader(forget_ds, batch_size=batch_size_f, shuffle=True, generator=G_forget)\n",
    "        validation_loader = DataLoader(val_ds, batch_size=batch_size_v, shuffle=True, generator=G_validate)\n",
    "\n",
    "        return retain_loader, forget_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc5a420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T05:58:10.672961Z",
     "iopub.status.busy": "2024-02-24T05:58:10.672183Z",
     "iopub.status.idle": "2024-02-24T05:58:10.689237Z",
     "shell.execute_reply": "2024-02-24T05:58:10.688499Z"
    },
    "id": "gwl18DEnMfGr",
    "papermill": {
     "duration": 0.033891,
     "end_time": "2024-02-24T05:58:10.691236",
     "exception": false,
     "start_time": "2024-02-24T05:58:10.657345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not test:\n",
    "\n",
    "    if os.path.exists('/kaggle/input/neurips-2023-machine-unlearning/empty.txt'):\n",
    "        # mock submission\n",
    "        subprocess.run('touch submission.zip', shell=True)\n",
    "    else:\n",
    "\n",
    "        # Note: it's really important to create the unlearned checkpoints outside of the working directory\n",
    "        # as otherwise this notebook may fail due to running out of disk space.\n",
    "        # The below code saves them in /kaggle/tmp to avoid that issue.\n",
    "\n",
    "        os.makedirs('/kaggle/tmp', exist_ok=True)\n",
    "#         retain_loader, forget_loader, validation_loader = get_dataset(512)\n",
    "        forget = get_dataset(64, 128, 64)\n",
    "        retain = get_dataset(256, 64, 64)\n",
    "        \n",
    "        net = resnet18(weights=None, num_classes=10)\n",
    "        net.to(DEVICE)\n",
    "        for i in range(512):\n",
    "            net.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n",
    "#             unlearning(net, retain_loader, forget_loader, validation_loader)\n",
    "            freezeBN(net)\n",
    "#             compareGradFlattenedAll2(net, forget[1], forget[0], 5, .0005, True)\n",
    "#             compareGradFlattenedAll2(net, retain[0], retain[1], 3, -.0005, True)\n",
    "\n",
    "#             compareGradFlattenedAll2(net, forget[1], forget[0], 3, .01, True)\n",
    "#             compareGradFlattenedAll2(net, forget[1], forget[0], 4, .005, True)\n",
    "#             compareGradFlattenedAll2(net, retain[0], retain[1],4, -.02, True)\n",
    "\n",
    "            compareGradFlattenedAll2(net, forget[1], forget[0], 5, .02, True, .9)\n",
    "            compareGradFlattenedAll2(net, retain[0], retain[1], 3, -.02, True,  .9)\n",
    "            \n",
    "#             compareGradFlattenedAll2(net, forget[1], forget[0], 4, .005, True)\n",
    "#             compareGradFlattenedAll2(net, retain[0], retain[1], 3, -.005, True)\n",
    "\n",
    "            state = net.state_dict()\n",
    "            torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
    "\n",
    "        # Ensure that submission.zip will contain exactly 512 checkpoints\n",
    "        # (if this is not the case, an exception will be thrown).\n",
    "        unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
    "        if len(unlearned_ckpts) != 512:\n",
    "            raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
    "\n",
    "        subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6535361,
     "sourceId": 56167,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30554,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.258945,
   "end_time": "2024-02-24T05:58:12.127862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-24T05:57:59.868917",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
